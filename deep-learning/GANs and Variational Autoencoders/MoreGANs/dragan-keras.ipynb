{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow' # 也可以使用 tensorflow\n",
    "#os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,exception_verbosity=high'\n",
    "os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_compile'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modifed from https://github.com/martinarjovsky/WassersteinGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DCGAN_D(isize, nz, nc, ndf, n_extra_layers=0):\n",
    "    assert isize%2==0\n",
    "    _ = inputs = Input(shape=(nc, isize, isize))\n",
    "    _ = Conv2D(filters=ndf, kernel_size=4, strides=2, use_bias=False,\n",
    "                        padding = \"same\",\n",
    "                        kernel_initializer = conv_init, \n",
    "                        name = 'initial.conv.{0}-{1}'.format(nc, ndf)             \n",
    "                        ) (_)\n",
    "    _ = LeakyReLU(alpha=0.2, name = 'initial.relu.{0}'.format(ndf))(_)\n",
    "    csize, cndf = isize// 2, ndf\n",
    "    while csize > 5:\n",
    "        assert csize%2==0\n",
    "        in_feat = cndf\n",
    "        out_feat = cndf*2\n",
    "        _ = Conv2D(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
    "                        padding = \"same\",\n",
    "                        kernel_initializer = conv_init,\n",
    "                        name = 'pyramid.{0}-{1}.conv'.format(in_feat, out_feat)             \n",
    "                        ) (_)\n",
    "        if 0: # toggle batchnormalization\n",
    "            _ = BatchNormalization(name = 'pyramid.{0}.batchnorm'.format(out_feat),                                   \n",
    "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init, \n",
    "                                  )(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2, name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
    "        csize, cndf = (csize+1)//2, cndf*2\n",
    "    _ = Conv2D(filters=1, kernel_size=csize, strides=1, use_bias=False,\n",
    "                        kernel_initializer = conv_init,\n",
    "                        name = 'final.{0}-{1}.conv'.format(cndf, 1)         \n",
    "                        ) (_)\n",
    "    outputs = Flatten()(_)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DCGAN_G(isize, nz, nc, ngf, n_extra_layers=0):\n",
    "    cngf= ngf//2\n",
    "    tisize = isize\n",
    "    while tisize > 5:\n",
    "        cngf = cngf * 2\n",
    "        assert tisize%2==0\n",
    "        tisize = tisize // 2\n",
    "    _ = inputs = Input(shape=(nz,))\n",
    "    _ = Reshape((nz, 1,1))(_)\n",
    "    _ = Conv2DTranspose(filters=cngf, kernel_size=tisize, strides=1, use_bias=False,\n",
    "                           kernel_initializer = conv_init, \n",
    "                           name = 'initial.{0}-{1}.convt'.format(nz, cngf))(_)\n",
    "    _ = BatchNormalization(gamma_initializer = gamma_init, momentum=0.9, axis=1, epsilon=1.01e-5,\n",
    "                               name = 'initial.{0}.batchnorm'.format(cngf))(_, training=1)\n",
    "    _ = Activation(\"relu\", name = 'initial.{0}.relu'.format(cngf))(_)\n",
    "    csize, cndf = tisize, cngf\n",
    "    \n",
    "\n",
    "    while csize < isize//2:\n",
    "        in_feat = cngf\n",
    "        out_feat = cngf//2\n",
    "        _ = Conv2DTranspose(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init, padding=\"same\",\n",
    "                        name = 'pyramid.{0}-{1}.convt'.format(in_feat, out_feat)             \n",
    "                        ) (_)\n",
    "        _ = BatchNormalization(gamma_initializer = gamma_init, \n",
    "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
    "                                   name = 'pyramid.{0}.batchnorm'.format(out_feat))(_, training=1)\n",
    "        \n",
    "        _ = Activation(\"relu\", name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
    "        csize, cngf = csize*2, cngf//2\n",
    "    _ = Conv2DTranspose(filters=nc, kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init, padding=\"same\",\n",
    "                        name = 'final.{0}-{1}.convt'.format(cngf, nc)\n",
    "                        )(_)\n",
    "    outputs = Activation(\"tanh\", name = 'final.{0}.tanh'.format(nc))(_)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "n_extra_layers = 0\n",
    "Diters = 5\n",
    "λ = 10\n",
    "\n",
    "imageSize = 32\n",
    "batchSize = 64\n",
    "lrD = 1e-4\n",
    "lrG = 1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netD = DCGAN_D(imageSize, nz, nc, ndf, n_extra_layers)\n",
    "netD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netG = DCGAN_G(imageSize, nz, nc, ngf, n_extra_layers)\n",
    "netG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute Wasserstein loss and  gradient penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netD_real_input = Input(shape=(nc, imageSize, imageSize))\n",
    "noisev = Input(shape=(nz,))\n",
    "netD_fake_input = netG(noisev)\n",
    "\n",
    "ϵ_input = K.placeholder(shape=(None, nc,imageSize,imageSize))\n",
    "netD_mixed_input = Input(shape=(nc, imageSize, imageSize),  tensor=netD_real_input + ϵ_input)\n",
    "\n",
    "\n",
    "loss_real = K.mean(netD(netD_real_input))\n",
    "loss_fake = K.mean(netD(netD_fake_input))\n",
    "\n",
    "grad_mixed = K.gradients(netD(netD_mixed_input), [netD_mixed_input])[0]\n",
    "norm_grad_mixed = K.sqrt(K.sum(K.square(grad_mixed), axis=[1,2,3]))\n",
    "grad_penalty = K.mean(K.square(norm_grad_mixed -1))\n",
    "\n",
    "loss = loss_fake - loss_real + λ * grad_penalty\n",
    "\n",
    "\n",
    "training_updates = Adam(lr=lrD).get_updates(netD.trainable_weights,[],loss)\n",
    "netD_train = K.function([netD_real_input, noisev, ϵ_input],\n",
    "                        [loss_real, loss_fake],    \n",
    "                        training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss for netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = -loss_fake \n",
    "training_updates = Adam(lr=lrG).get_updates(netG.trainable_weights,[], loss)\n",
    "netG_train = K.function([noisev], [loss], training_updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Download CIFAR10 if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tarfile\n",
    "\n",
    "# Download dataset\n",
    "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "import os\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "def reporthook(a,b,c):\n",
    "    print(\"\\rdownloading: %5.1f%%\"%(a*b*100.0/c), end=\"\")\n",
    "tar_gz = \"cifar-10-python.tar.gz\"\n",
    "if not os.path.isfile(tar_gz):\n",
    "        print('Downloading data from %s' % url)\n",
    "        urlretrieve(url, tar_gz, reporthook=reporthook)\n",
    "\n",
    "import pickle\n",
    "train_X=[]\n",
    "train_y=[]\n",
    "tar_gz = \"cifar-10-python.tar.gz\"\n",
    "with tarfile.open(tar_gz) as tarf:\n",
    "    for i in range(1, 6):\n",
    "        dataset = \"cifar-10-batches-py/data_batch_%d\"%i\n",
    "        print(\"load\",dataset)\n",
    "        with tarf.extractfile(dataset) as f:\n",
    "            result = pickle.load(f, encoding='latin1')\n",
    "        train_X.extend( result['data'].reshape(-1,3,32,32)/255*2-1)\n",
    "        train_y.extend(result['labels'])\n",
    "    train_X=np.float32(train_X)\n",
    "    train_y=np.int32(train_y)\n",
    "    dataset = \"cifar-10-batches-py/test_batch\"\n",
    "    print(\"load\",dataset)\n",
    "    with tarf.extractfile(dataset) as f:\n",
    "        result = pickle.load(f, encoding='latin1')\n",
    "        test_X=np.float32(result['data'].reshape(-1,3,32,32)/255*2-1)\n",
    "        test_y=np.int32(result['labels'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also using test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_X = np.concatenate([train_X[:,:,:,::-1], train_X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utility to show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "    # N*3072 -> N*3*32*32 -> 32 * 32N * 3\n",
    "    int_X = np.moveaxis(int_X.reshape(-1,3,32,32), 1, 3)\n",
    "    int_X = int_X.reshape(rows, -1, 32, 32,3).swapaxes(1,2).reshape(rows*32,-1, 3)\n",
    "    display(Image.fromarray(int_X))\n",
    "# 訓練資料， X 的前 20 筆\n",
    "showX(train_X[:20])\n",
    "print(train_y[:20])\n",
    "name_array = np.array(\"airplane car bird cat deer dog frog horse boat truck\".split(' '))\n",
    "print(name_array[train_y[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_noise = np.random.normal(size=(batchSize, nz)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "niter = 100\n",
    "gen_iterations = 0\n",
    "errG = 0\n",
    "targetD = np.float32([2]*batchSize+[-2]*batchSize)[:, None]\n",
    "targetG = np.ones(batchSize, dtype=np.float32)[:, None]\n",
    "for epoch in range(niter):\n",
    "    i = 0\n",
    "    #  每個 epoch 洗牌一下\n",
    "    np.random.shuffle(train_X)\n",
    "    batches = train_X.shape[0]//batchSize\n",
    "    while i < batches:\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            _Diters = 100\n",
    "        else:\n",
    "            _Diters = Diters\n",
    "        j = 0\n",
    "        while j < _Diters and i < batches:\n",
    "            j+=1\n",
    "            real_data = train_X[i*batchSize:(i+1)*batchSize]\n",
    "            i+=1\n",
    "            noise = np.random.normal(size=(batchSize, nz))        \n",
    "            ϵ = real_data.std() * np.random.uniform(-0.5,0.5, size=real_data.shape) \n",
    "            ϵ *= np.random.uniform(size=(batchSize, 1,1,1))\n",
    "            errD_real, errD_fake  = netD_train([real_data, noise, ϵ]) \n",
    "            errD = errD_real - errD_fake\n",
    "       \n",
    "        if gen_iterations%500==0:\n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, niter, i, batches, gen_iterations,errD, errG, errD_real, errD_fake), time.time()-t0)\n",
    "            fake = netG.predict(fixed_noise)\n",
    "            showX(fake, 4)\n",
    "        \n",
    "        noise = np.random.normal(size=(batchSize, nz))        \n",
    "        errG, = netG_train([noise])\n",
    "        gen_iterations+=1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
