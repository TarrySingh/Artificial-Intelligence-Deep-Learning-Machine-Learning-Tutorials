{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_004 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "PATH = DATA_PATH/'caltech101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std = map(tensor, ([0.5355,0.5430,0.5280], [0.2909,0.2788,0.2979]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, fns, labels, classes=None):\n",
    "        if classes is None: classes = list(set(labels))\n",
    "        self.classes = classes\n",
    "        self.class2idx = {v:k for k,v in enumerate(classes)}\n",
    "        self.fns = np.array(fns)\n",
    "        self.y = [self.class2idx[o] for o in labels]\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, classes=None, test_pct=0., tfms=None):\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "            \n",
    "        fns,labels = [],[]\n",
    "        for cl in classes:\n",
    "            fnames = get_image_files(folder/cl)\n",
    "            fns += fnames\n",
    "            labels += [cl] * len(fnames)\n",
    "            \n",
    "        if test_pct==0.: return cls(fns, labels)\n",
    "        fns,labels = np.array(fns),np.array(labels)\n",
    "        is_test = np.random.uniform(size=(len(fns),)) < test_pct\n",
    "        return cls(fns[~is_test], labels[~is_test]), cls(fns[is_test], labels[is_test])\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_transform\n",
    "def crop_with_ratio(x, scale:uniform, ratio:uniform, invert:rand_bool, row_pct:uniform, col_pct:uniform) -> TfmType.Start:\n",
    "    #scale, ratio and invert are supposed to have a size corresponding to the number of attempts before fallback.\n",
    "    for s,r,i in zip(scale, ratio, invert):\n",
    "        area = x.size(1) * x.size(2)\n",
    "        target_area = area * s\n",
    "        cols = int(round(math.sqrt(target_area * r)))\n",
    "        rows = int(round(math.sqrt(target_area / r)))\n",
    "\n",
    "        if i: cols,rows = rows,cols\n",
    "\n",
    "        if cols <= x.size(2) and rows <= x.size(1):\n",
    "            row = int((x.size(1)-rows+1)*row_pct)\n",
    "            col = int((x.size(2)-cols+1)*col_pct)\n",
    "            return x[:, row:row+rows, col:col+cols].contiguous()\n",
    "    # Fallback\n",
    "    rows = min(x.size(1), x.size(2))\n",
    "    row = (x.size(1) - rows) // 2\n",
    "    col = (x.size(2) - rows) // 2\n",
    "    return x[:, row:row+rows, col:col+rows].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_transform\n",
    "def center_crop(x, b:uniform=0.5) -> TfmType.Pixel:\n",
    "    rows = min(x.size(1), x.size(2))\n",
    "    row = (x.size(1) - rows) // 2\n",
    "    col = (x.size(2) - rows) // 2\n",
    "    return x[:, row:row+rows, col:col+rows].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_resized_crop = crop_with_ratio_tfm(scale=(0.5,1.,10), ratio=(0.75,1.33,10),invert=(0.5,10),\n",
    "#                                          row_pct=(0,1.), col_pct=(0,1.))\n",
    "random_resized_crop = zoom_squish_tfm(scale=(0.5,1,10), squish=(0.75,1.33,10), invert=(0.5,10),\n",
    "                                      row_pct=(0,1.), col_pct=(0,1.))\n",
    "center_crop1 = zoom_squish_tfm(scale=(1.1,1.1,2), squish=(1,1,2), invert=(0.5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "trn_tfms = [random_resized_crop,\n",
    "            flip_lr_tfm(p=0.5),\n",
    "            normalize_tfm(mean=data_mean,std=data_std)] #torchvision.transforms.RandomRotation(10),\n",
    "val_tfms = [center_crop1,\n",
    "            normalize_tfm(mean=data_mean,std=data_std)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['airplanes','Motorbikes','Faces','watch','Leopards']\n",
    "np.random.seed(42)\n",
    "train_ds,valid_ds = ImageDataset.from_folder(PATH, test_pct=0.2)\n",
    "classes = train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TfmDataset(train_ds, trn_tfms, size=224)\n",
    "valid_ds = TfmDataset(valid_ds, val_tfms, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[0]\n",
    "x,y = valid_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_ds, valid_ds, bs=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks//2),\n",
    "        nn.BatchNorm2d(nf),\n",
    "        nn.LeakyReLU(negative_slope=0.1, inplace=True))\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, ni):\n",
    "        super().__init__()\n",
    "        self.conv1=conv_layer(ni, ni//2, ks=1)\n",
    "        self.conv2=conv_layer(ni//2, ni, ks=3)\n",
    "        \n",
    "    def forward(self, x): return x + self.conv2(self.conv1(x))\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    def make_group_layer(self, ch_in, num_blocks, stride=1):\n",
    "        return [conv_layer(ch_in, ch_in*2,stride=stride)\n",
    "               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes, nf=32):\n",
    "        super().__init__()\n",
    "        layers = [conv_layer(3, nf, ks=3, stride=1)]\n",
    "        for i,nb in enumerate(num_blocks):\n",
    "            layers += self.make_group_layer(nf, nb, stride=2-(i==1))\n",
    "            nf *= 2\n",
    "        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 4, 6, 2, 1], num_classes=len(classes), nf=16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder(Callback):\n",
    "    beta = 0.98\n",
    "    \n",
    "    def __init__(self, opt, train_dl=None):\n",
    "        self.opt,self.train_dl = opt,train_dl\n",
    "    \n",
    "    def on_train_begin(self):\n",
    "        self.epoch,self.n,self.avg_loss = 0,0,0.\n",
    "        self.losses,self.val_losses,self.lrs,self.moms,self.metrics = [],[],[],[],[]\n",
    "    \n",
    "    def on_batch_begin(self, xb, yb):\n",
    "        self.lrs.append(self.opt.lr)\n",
    "        self.moms.append(self.opt.mom)\n",
    "        return xb, yb\n",
    "    \n",
    "    def on_backward_begin(self, loss, out):\n",
    "        #We record the loss here before any other callback has a chance to modify it.\n",
    "        self.n += 1\n",
    "        self.avg_loss = self.beta * self.avg_loss + (1-self.beta) * loss.item()\n",
    "        self.smooth_loss = self.avg_loss / (1 - self.beta ** self.n)\n",
    "        self.losses.append(self.smooth_loss)\n",
    "        if self.train_dl is not None and self.train_dl.progress_func is not None: \n",
    "            self.train_dl.gen.set_postfix_str(self.smooth_loss)\n",
    "    \n",
    "    def on_epoch_end(self, val_metrics):\n",
    "        if val_metrics is not None:\n",
    "            self.val_losses.append(val_metrics[0])\n",
    "            if len(val_metrics) > 1: self.metrics.append(val_metrics[1:])\n",
    "            print(self.epoch, self.smooth_loss, *val_metrics)\n",
    "        self.epoch += 1\n",
    "    \n",
    "    def plot_lr(self, show_moms=False):\n",
    "        iterations = list(range(len(learn.recorder.lrs)))\n",
    "        if show_moms:\n",
    "            fig, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "            axs[0].plot(iterations, self.lrs)\n",
    "            axs[1].plot(iterations, self.moms)\n",
    "        else: plt.plot(iterations, self.lrs)\n",
    "    \n",
    "    def plot(self, skip_start=10, skip_end=5):\n",
    "        lrs = self.lrs[skip_start:-skip_end] if skip_end > 0 else self.lrs[skip_start:]\n",
    "        losses = self.losses[skip_start:-skip_end] if skip_end > 0 else self.losses[skip_start:]\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.plot(lrs, losses)\n",
    "        ax.set_xscale('log') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First training: SGD with 1cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.max(out, dim=1)[1]\n",
    "    return (preds==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Learner():\n",
    "    \n",
    "    loss_fn: Callable = F.cross_entropy\n",
    "    opt_fn: Callable = optim.SGD\n",
    "    metrics: List = None\n",
    "    \n",
    "    def __init__(self, data, model):\n",
    "        self.data,self.model = data,model.to(data.device)\n",
    "\n",
    "    def fit(self, epochs, lr, wd=0, callbacks=None):\n",
    "        self.opt = HPOptimizer(self.model.parameters(), self.opt_fn, init_lr=lr)\n",
    "        self.opt.wd = wd\n",
    "        self.recorder = Recorder(self.opt, self.data.train_dl)\n",
    "        callbacks.insert(0, self.recorder)\n",
    "        fit(epochs, self.model, self.loss_fn, self.opt, self.data, callbacks=callbacks, metrics=self.metrics)\n",
    "        \n",
    "    def lr_find(self, start_lr=1e-5, end_lr=10, num_it=200):\n",
    "        cb = LRFinder(self, start_lr, end_lr, num_it)\n",
    "        a = int(np.ceil(num_it/len(self.data.train_dl)))\n",
    "        self.fit(a, start_lr, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def loss_batch(model, xb, yb, loss_fn, opt=None, cb_handler=None, metrics=None):\n",
    "    out = model(xb)\n",
    "    loss = loss_fn(out, yb)\n",
    "    mets = [f(out,yb).item() for f in metrics] if metrics is not None else []\n",
    "    \n",
    "    if opt is not None:\n",
    "        if cb_handler is not None: loss = cb_handler.on_backward_begin(loss, out)\n",
    "        loss.backward()\n",
    "        if cb_handler is not None: cb_handler.on_backward_end()\n",
    "        opt.step()\n",
    "        if cb_handler is not None: cb_handler.on_step_end()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return (loss.item(),) + tuple(mets) + (len(xb),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fit(epochs, model, loss_fn, opt, data, callbacks=None, metrics=None):\n",
    "    \n",
    "    cb_handler = CallbackHandler(callbacks)\n",
    "    cb_handler.on_train_begin()\n",
    "    \n",
    "    for epoch in tnrange(epochs):\n",
    "        model.train()\n",
    "        cb_handler.on_epoch_begin()\n",
    "        \n",
    "        for xb,yb in data.train_dl:\n",
    "            xb, yb = cb_handler.on_batch_begin(xb, yb)\n",
    "            loss,_ = loss_batch(model, xb, yb, loss_fn, opt, cb_handler)\n",
    "            if cb_handler.on_batch_end(loss): break\n",
    "        \n",
    "        if hasattr(data,'valid_dl') and data.valid_dl is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                *val_metrics,nums = zip(*[loss_batch(model, xb, yb, loss_fn, metrics=metrics)\n",
    "                                for xb,yb in data.valid_dl])\n",
    "            val_metrics = [np.sum(np.multiply(val,nums)) / np.sum(nums) for val in val_metrics]\n",
    "            \n",
    "        else: val_metrics=None\n",
    "        if cb_handler.on_epoch_end(val_metrics): break\n",
    "        \n",
    "    cb_handler.on_train_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueWD(Callback):\n",
    "    \n",
    "    def __init__(self, learn, wd):\n",
    "        self.learn,self.wd = learn,wd\n",
    "        \n",
    "    def on_train_begin(self):\n",
    "        self.opt = self.learn.opt\n",
    "        self.opt.wd = 0\n",
    "        \n",
    "    def on_backward_end(self):\n",
    "        for pg in self.opt.opt.param_groups:\n",
    "            for p in pg['params']:\n",
    "                p.data.mul_(1 - self.wd * pg['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 4, 6, 3], num_classes=len(classes), nf=16).cuda()\n",
    "learn = Learner(data, model)\n",
    "learn.loss_fn = F.cross_entropy\n",
    "learn.metrics = [accuracy]\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.95,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheds = [OneCycleScheduler(learn, 4e-3, 30, div_factor=10, pct_end=0.1), TrueWD(learn, 0.3)]\n",
    "learn.fit(30, 2e-3, wd=1e-4, callbacks=scheds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2e-3, 0.1, 76.4%\n",
    "1e-3, 0.1, 76.3%\n",
    "5e-4, 0.1, 76.5%\n",
    "4e-3, 0.1, 77.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With perspective wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coeffs(ori_pts, targ_pts):\n",
    "    matrix = []\n",
    "    for p1, p2 in zip(targ_pts, ori_pts):\n",
    "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
    "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
    "\n",
    "    A = FloatTensor(matrix)\n",
    "    B = FloatTensor(ori_pts).view(8)\n",
    "    #The 8 scalars we seek are solution of AX = B, we use the pseudo inverse to compute them.\n",
    "    \n",
    "    res = torch.mv(torch.mm(torch.inverse(torch.mm(A.t(),A)), A.t()), B)\n",
    "    #res = numpy.dot(numpy.linalg.inv(A.T * A) * A.T, B)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ones(coords):\n",
    "    coords = coords.view(-1,2)\n",
    "    ones = torch.ones(coords.size(0)).unsqueeze(1)\n",
    "    coords = torch.cat([coords, ones], 1)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective(coords, coeffs):\n",
    "    ori_size = coords.size()\n",
    "    #compress all the dims expect the last one ang adds ones, coords become N * 3\n",
    "    coords = add_ones(coords)\n",
    "    #Transform the coeffs in a 3*3 matrix with a 1 at the bottom left\n",
    "    coeffs = torch.cat([coeffs, FloatTensor([1])]).view(3,3)\n",
    "    coords = torch.mm(coords, coeffs.t())\n",
    "    coords.mul_(1/coords[:,2].unsqueeze(1))\n",
    "    return coords[:,:2].view(ori_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_transform\n",
    "def perspective_warp(c, img_size, magnitude:uniform=0) -> TfmType.Coord:\n",
    "    magnitude = magnitude.view(4,2)\n",
    "    ori_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n",
    "    targ_pts = [[x+m for x,m in zip(xs, ms)] for xs, ms in zip(ori_pts, magnitude)]\n",
    "    coeffs = find_coeffs(ori_pts, targ_pts)\n",
    "    return apply_perspective(c, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_int(low,high): return random.randint(low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_affine\n",
    "def zoom(scale: uniform = 1.0, row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Affine:\n",
    "    s = 1-1/scale\n",
    "    col_c = s * (2*col_pct - 1)\n",
    "    row_c = s * (2*row_pct - 1)\n",
    "    return [[1/scale, 0,       col_c],\n",
    "            [0,       1/scale, row_c],\n",
    "            [0,       0,       1.    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_transform\n",
    "def tilt(c, img_size, direction:rand_int, magnitude:uniform=0) -> TfmType.Coord:\n",
    "    ori_pts = [[-1,-1], [-1,1], [1,-1], [1,1]]\n",
    "    if direction == 0:   targ_pts = [[-1,-1], [-1,1], [1,-1-magnitude], [1,1+magnitude]]\n",
    "    elif direction == 1: targ_pts = [[-1,-1-magnitude], [-1,1+magnitude], [1,-1], [1,1]]\n",
    "    elif direction == 2: targ_pts = [[-1,-1], [-1-magnitude,1], [1,-1], [1+magnitude,1]]\n",
    "    elif direction == 3: targ_pts = [[-1-magnitude,-1], [-1,1], [1+magnitude,-1], [1,1]]  \n",
    "    coeffs = find_coeffs(ori_pts, targ_pts)\n",
    "    return apply_perspective(c, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_affine\n",
    "def zoom1(scale: uniform = 1.0, row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Affine:\n",
    "    s = 1-math.sqrt(scale)\n",
    "    col_c = s * (2*col_pct - 1)\n",
    "    row_c = s * (2*row_pct - 1)\n",
    "    return [[math.sqrt(scale), 0,       col_c],\n",
    "            [0,       math.sqrt(scale), row_c],\n",
    "            [0,       0,       1.    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reg_affine\n",
    "def stretch(scale: uniform = 1.0) -> TfmType.Affine:\n",
    "    return [[math.sqrt(scale), 0,       0],\n",
    "            [0,       1/math.sqrt(scale), 0],\n",
    "            [0,       0,       1.    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "trn_tfms = [stretch_tfm(scale=(0.75,1.33)),\n",
    "            zoom_tfm(scale=(0.08,0.8), row_pct=(0,1.), col_pct=(0,1.)),\n",
    "            flip_lr_tfm(p=0.5),\n",
    "            center_crop_tfm(b=(0,1)),\n",
    "            normalize_tfm(mean=data_mean,std=data_std)] #torchvision.transforms.RandomRotation(10),\n",
    "val_tfms = [center_crop_tfm(b=(0,1)),\n",
    "            normalize_tfm(mean=data_mean,std=data_std)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['airplanes','Motorbikes','Faces','watch','Leopards']\n",
    "np.random.seed(42)\n",
    "train_ds,valid_ds = ImageDataset.from_folder(PATH, test_pct=0.2)\n",
    "classes = train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TfmDataset(train_ds, trn_tfms, size=224)\n",
    "valid_ds = TfmDataset(valid_ds, val_tfms, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[0]\n",
    "x,y = valid_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_ds, valid_ds, bs=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 4, 6, 3], num_classes=len(classes), nf=16).cuda()\n",
    "learn = Learner(data, model)\n",
    "learn.loss_fn = F.cross_entropy\n",
    "learn.metrics = [accuracy]\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.95,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheds = [OneCycleScheduler(learn, 4e-3, 30, div_factor=10, pct_end=0.1), TrueWD(learn, 0.1)]\n",
    "learn.fit(30, 2e-3, wd=1e-4, callbacks=scheds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_batch(data.train_dl, classes, rows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
