{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nb_002 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "PATH = DATA_PATH/'imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of all the different possiblities for a pipeline on imagenet including:\n",
    "- resizing the image so that the lower dimension is 224\n",
    "- random rotate -10 to 10 degrees\n",
    "- random scale 0.9 to 1.1\n",
    "- random flip\n",
    "- random crop\n",
    "\n",
    "Test on the first 100 batches of imagenet (with shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVImageDataset(Dataset):\n",
    "    def __init__(self, folder, tfms):\n",
    "        cls_dirs = find_classes(folder)\n",
    "        self.fns, self.y = [], []\n",
    "        self.classes = [cls.name for cls in cls_dirs]\n",
    "        for i, cls_dir in enumerate(cls_dirs):\n",
    "            fnames = get_image_files(cls_dir)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.tfms = torchvision.transforms.Compose(tfms)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = Image.open(self.fns[i]).convert('RGB')\n",
    "        x = self.tfms(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 192\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [torchvision.transforms.RandomRotation(10),\n",
    "              torchvision.transforms.RandomResizedCrop(sz, scale=(0.5, 1.0), ratio=(1.,1.)),\n",
    "              torchvision.transforms.RandomHorizontalFlip(),\n",
    "              torchvision.transforms.ToTensor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TVImageDataset(PATH/'train', train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_device = default_device = torch.device('cuda', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with grid_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs the PR https://github.com/pytorch/pytorch/pull/9961/files to make grid_sample fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def resolve_pipeline(tfms, **kwargs):\n",
    "    tfms = listify(tfms)\n",
    "    if len(tfms)==0: return noop\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    lighting_tfms,coord_tfms,affine_tfms,pixel_tfms,final_tfms = map(grouped_tfms.get, TfmType)\n",
    "    lighting_tfm = apply_lighting_tfms(lighting_tfms)\n",
    "    affine_tfm = compose_affine_tfms(affine_tfms, funcs=coord_tfms, **kwargs)\n",
    "    pixel_tfm = compose_tfms(pixel_tfms)\n",
    "    final_tfm = compose_tfms(final_tfms)\n",
    "    return lambda x,**k: final_tfm(affine_tfm(lighting_tfm(pixel_tfm(x)), **k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31.5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now without affine augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        w,h = x.size\n",
    "        if w < h: w,h = self.sz,int(self.sz * h / w)\n",
    "        else:     w,h = int(self.sz * w / h),self.sz\n",
    "        theta = random.uniform(-10,10) * math.pi / 180 if random.random() < 0.75 else 0\n",
    "        scale = random.uniform(0.9,1.1) if random.random() < 0.75 else 1\n",
    "        x = x.transform((w,h), Image.AFFINE, (cos(theta)/scale, -sin(theta), 0, sin(theta), cos(theta)/scale, 0), Image.BILINEAR)\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75), Those are done in the dataset\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.8s ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just PIL resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        w,h = x.size\n",
    "        if w < h: w,h = self.sz,int(self.sz * h / w)\n",
    "        else:     w,h = int(self.sz * w / h),self.sz\n",
    "        x = x.resize((w,h))\n",
    "        x = pil2tensor(x)\n",
    "        x = F.interpolate(x[None], size=(self.sz,self.sz),mode='bilinear')\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x[0]) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just F.interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        x = F.interpolate(x[None], size=(self.sz,self.sz),mode='bilinear')\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x[0]) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              #zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              #rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_sample used to be faster on the GPU so let's try to do that step there by moving the image on the GPU during the affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_affine(img, m=None, func=None, size=None, **kwargs):\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    if size is None: size = img.size()\n",
    "    elif isinstance(size, int):\n",
    "        if img.size(1) < img.size(2): size = (img.size(0),size,int(img.size(2)*size/img.size(1)))\n",
    "        else: size = (img.size(0),int(img.size(1)*size/img.size(2)),size)\n",
    "    if m is None:\n",
    "        if img.shape==size: return img\n",
    "        else: m=eye_new(img, 3)\n",
    "    m = m.cuda(non_blocking=True)\n",
    "    c = affine_grid(img,  img.new_tensor(m), size=size)\n",
    "    if func is not None: c = func(c)\n",
    "    return grid_sample(img, c, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def resolve_pipeline(tfms, **kwargs):\n",
    "    tfms = listify(tfms)\n",
    "    if len(tfms)==0: return noop\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    lighting_tfms,coord_tfms,affine_tfms,pixel_tfms,final_tfms = map(grouped_tfms.get, TfmType)\n",
    "    lighting_tfm = apply_lighting_tfms(lighting_tfms)\n",
    "    affine_tfm = compose_affine_tfms(affine_tfms, funcs=coord_tfms, **kwargs)\n",
    "    pixel_tfm = compose_tfms(pixel_tfms)\n",
    "    final_tfm = compose_tfms(final_tfms)\n",
    "    return lambda x,**k: final_tfm(affine_tfm(lighting_tfm(pixel_tfm(x)), **k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 64\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5),\n",
    "              zoom_tfm(scale=(0.9,1.1),p=0.75),\n",
    "              rotate_tfm(degrees=(-10,10.),p=0.75),\n",
    "              crop_tfm(size=sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            #x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m[None,:,None,None]) / self.s[None,:,None,None]\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))\n",
    "\n",
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "%time for i in tqdm(range(100)): x,y = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant change from the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
