{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_007b import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('../data/aclImdb/clas/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's assumed that CLAS_PATH contains the files itos.pkl, trian_ids.npy, valid_ids.npy, trian_lbl.npy and valid_lbl.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = TextDataset.from_ids(CLAS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 48,70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SortSampler(train_ds.ids, key=lambda x: len(train_ds.ids[x]))\n",
    "valid_sampler = SortSampler(valid_ds.ids, key=lambda x: len(valid_ds.ids[x]))\n",
    "train_dl = DeviceDataLoader.create(train_ds, bs//2, sampler=train_sampler, collate_fn=pad_collate)\n",
    "valid_dl = DeviceDataLoader.create(valid_ds, bs,  sampler=valid_sampler, collate_fn=pad_collate)\n",
    "data = DataBunch(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size,n_class = len(train_ds.vocab.itos),2\n",
    "emb_sz,nh,nl = 400,1150,3\n",
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_rnn_classifier(bptt, 20*70, n_class, vocab_size, emb_sz=emb_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[emb_sz*3, 50, n_class], drops=[dps[4], 0.1],\n",
    "          input_p=dps[0], weight_p=dps[1], embed_p=dps[2], hidden_p=dps[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model[0].state_dict(), 'models/body.pth')\n",
    "#torch.save(model[1].state_dict(), 'models/head.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [nn.Sequential(model[0].encoder, model[0].encoder_dp)]\n",
    "groups += [nn.Sequential(rnn, dp) for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)] \n",
    "groups.append(model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model)\n",
    "learn.layer_groups = groups\n",
    "learn.callbacks.append(RNNTrainer(learn, bptt, alpha=2, beta=1, adjust=False))\n",
    "learn.callback_fns.append(partial(GradientClipping, clip=0.12))\n",
    "learn.metrics = [accuracy]\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model[0].load_state_dict(torch.load('models/body.pth'))\n",
    "learn.model[1].load_state_dict(torch.load('models/head.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1, 1e-2, wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.losses[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('../data/aclImdb/clas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = pickle.load(open(CLAS_PATH/'tmp'/'itos.pkl', 'rb'))\n",
    "trn_clas = np.load(CLAS_PATH/'tmp'/'train_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'valid_ids.npy')\n",
    "trn_labels = np.load(CLAS_PATH/'tmp'/'train_lbl.npy')\n",
    "val_labels = np.load(CLAS_PATH/'tmp'/'valid_lbl.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48\n",
    "wd=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortSampler(trn_clas, key=lambda x: len(trn_clas[x]))\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(CLAS_PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=0.12\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path('models/')\n",
    "body = torch.load(MODEL_PATH/'body.pth', map_location='cuda')\n",
    "head = torch.load(MODEL_PATH/'head.pth', map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {'encoder_dp.emb.weight':'encoder_with_dropout.embed.weight'}\n",
    "for i in range(3): replace[f'rnns.{i}.weight_hh_l0_raw'] = f'rnns.{i}.module.weight_hh_l0_raw'\n",
    "to_del = [f'rnns.{i}.module.weight_hh_l0' for i in range(3)]\n",
    "new_body = {}\n",
    "for n,p in body.items():\n",
    "    n1 = replace[n] if n in replace else n\n",
    "    if not n in to_del: new_body[n1] = model[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {'layers.2.weight':'layers.0.lin.weight',\n",
    "           'layers.2.bias':'layers.0.lin.bias',\n",
    "           'layers.0.weight':'layers.0.bn.weight',\n",
    "           'layers.0.bias':'layers.0.bn.bias',\n",
    "           'layers.0.running_mean':'layers.0.bn.running_mean',\n",
    "           'layers.0.running_var':'layers.0.bn.running_var',\n",
    "           'layers.6.weight':'layers.1.lin.weight',\n",
    "           'layers.6.bias':'layers.1.lin.bias',\n",
    "           'layers.4.weight':'layers.1.bn.weight',\n",
    "           'layers.4.bias':'layers.1.bn.bias',\n",
    "           'layers.4.running_mean':'layers.1.bn.running_mean',\n",
    "           'layers.4.running_var':'layers.1.bn.running_var',\n",
    "           }\n",
    "new_head = {}\n",
    "for n,p in head.items():\n",
    "    if n in replace: new_head[replace[n]] = p.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0].load_state_dict(new_body)\n",
    "m[1].load_state_dict(new_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr,wd=1e-2,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.losses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
