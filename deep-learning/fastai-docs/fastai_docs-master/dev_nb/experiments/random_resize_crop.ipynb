{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from nb_002 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "DATA_PATH = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "PATH = DATA_PATH/'imagenet'\n",
    "list_classes = find_classes(PATH/'train')\n",
    "\n",
    "np.random.seed(42)\n",
    "random_select = np.random.permutation(list_classes)[:4]\n",
    "\n",
    "def get_val_folders(class_folders):\n",
    "    names = [f.name for f in class_folders]\n",
    "    return [PATH/'val'/name for name in names]\n",
    "\n",
    "def create_new(class_folders):\n",
    "    path = Path('../data/sample_imagenet/')\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for mode in ['train', 'val']:\n",
    "        p = path/mode\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "        for f in class_folders:\n",
    "            os.makedirs(p/f.name, exist_ok=True)\n",
    "            list_images = (PATH/mode/f.name).glob('*')\n",
    "            for img in list_images: shutil.copy(img, p/f.name/img.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to create the random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_new(random_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = DATA_PATH/'sample_imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of all the different possiblities for a pipeline on imagenet including:\n",
    "- resizing the image so that the lower dimension is 224\n",
    "- random rotate -10 to 10 degrees\n",
    "- random scale 0.9 to 1.1\n",
    "- random flip\n",
    "- random crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVImageDataset(Dataset):\n",
    "    def __init__(self, folder, tfms):\n",
    "        cls_dirs = find_classes(folder)\n",
    "        self.fns, self.y = [], []\n",
    "        self.classes = [cls.name for cls in cls_dirs]\n",
    "        for i, cls_dir in enumerate(cls_dirs):\n",
    "            fnames = get_image_files(cls_dir)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.tfms = torchvision.transforms.Compose(tfms)\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = Image.open(self.fns[i]).convert('RGB')\n",
    "        x = self.tfms(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device)[None,:,None,None], stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            x, y = b[0].to(self.device),b[1].to(self.device)\n",
    "            x = (x - self.m) / self.s\n",
    "            yield x,y\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, stats, device = None, sampler=None):\n",
    "    if device is None: device = default_device\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz, bs = 224, 192\n",
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [torchvision.transforms.RandomResizedCrop(sz),\n",
    "              torchvision.transforms.RandomHorizontalFlip(),\n",
    "              torchvision.transforms.ToTensor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TVImageDataset(PATH/'train', train_tfms)\n",
    "default_device = default_device = torch.device('cuda', 0)\n",
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)\n",
    "len(train_ds),len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for x,y in tqdm(iter(train_dl), total=len(train_dl)): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with grid_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs the PR https://github.com/pytorch/pytorch/pull/10051/files to make grid_sample fast and support reflect padding/nearest interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_groupby(iterable, key=None):\n",
    "    return {k:list(v) for k,v in itertools.groupby(sorted(iterable, key=key), key=key)}\n",
    "\n",
    "def resolve_pipeline(tfms, **kwargs):\n",
    "    if len(tfms)==0: return noop\n",
    "    grouped_tfms = dict_groupby(tfms, lambda o: o.__annotations__['return'])\n",
    "    lighting_tfms,coord_tfms,affine_tfms,pixel_tfms,final_tfms = [\n",
    "        resolve_tfms(grouped_tfms.get(o)) for o in TfmType]\n",
    "    lighting_tfm = apply_lighting_tfm(compose(lighting_tfms))\n",
    "    affine_tfm = apply_affine_tfm(affine_tfms, func=compose(coord_tfms), **kwargs)\n",
    "    final_tfm = compose(final_tfms)\n",
    "    pixel_tfm = compose(pixel_tfms)\n",
    "\n",
    "    return lambda x,**k: lighting_tfm(final_tfm(affine_tfm(pixel_tfm(x.clone()), **k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rrc_params(img, scale, ratio):\n",
    "    for attempt in range(10):\n",
    "        area = img.size[0] * img.size[1]\n",
    "        target_area = random.uniform(*scale) * area\n",
    "        aspect_ratio = random.uniform(*ratio)\n",
    "\n",
    "        w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "\n",
    "        if w <= img.size[0] and h <= img.size[1]:\n",
    "            i = random.randint(0, img.size[1] - h)\n",
    "            j = random.randint(0, img.size[0] - w)\n",
    "            return i, j, h, w\n",
    "\n",
    "    w = min(img.size[0], img.size[1])\n",
    "    i = (img.size[1] - w) // 2\n",
    "    j = (img.size[0] - w) // 2\n",
    "    return i, j, w, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = pil2tensor(x)\n",
    "        x = x[:,i:i+h,j:j+w]\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)\n",
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)\n",
    "len(train_ds),len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for x,y in tqdm(iter(train_dl), total=len(train_dl)): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ToTensor() to pil2tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = torchvision.transforms.ToTensor()(x)\n",
    "        x = x[:,i:i+h,j:j+w]\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms, size=self.sz)(x) \n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)\n",
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for x,y in tqdm(iter(train_dl), total=len(train_dl)): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = x.crop((j,i,j+w,i+h))\n",
    "        x = x.resize((self.sz,self.sz), Image.BILINEAR)\n",
    "        x = pil2tensor(x)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)\n",
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for x,y in tqdm(iter(train_dl), total=len(train_dl)): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image((x*train_dl.s+train_dl.m)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just F.interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageDataset(Dataset):\n",
    "    def __init__(self, folder, sz, tfms=None, classes=None):\n",
    "        self.fns, self.y = [], []\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "        self.classes = classes\n",
    "        for i, cls in enumerate(classes):\n",
    "            fnames = get_image_files(folder/cls)\n",
    "            self.fns += fnames\n",
    "            self.y += [i] * len(fnames)\n",
    "        self.sz, self.tfms = sz, tfms\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        i,j,h,w = get_rrc_params(x, (0.8,1), (3/4,4/3))\n",
    "        x = pil2tensor(x)\n",
    "        x = x[:,i:i+h,j:j+w]\n",
    "        x = F.interpolate(x[None], size=(self.sz,self.sz),mode='bilinear', align_corners=True)\n",
    "        if self.tfms is not None:\n",
    "            x = resolve_pipeline(self.tfms)(x)\n",
    "        return x,self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    "train_tfms = [flip_lr_tfm(p=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TransformedImageDataset(PATH/'train', sz, train_tfms)\n",
    "train_dl = get_dataloader(train_ds, bs, shuffle=False, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for x,y in tqdm(iter(train_dl), total=len(train_dl)): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
