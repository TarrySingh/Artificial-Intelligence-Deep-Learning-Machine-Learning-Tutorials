{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from collections import namedtuple\n",
    "from common.params_inf import *\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force one-gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Numpy:  1.14.1\n",
      "GPU:  ['Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB']\n",
      "CUDA Version 8.0.61\n",
      "CuDNN Version  6.0.21\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple('Batch', ['data'])\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 224, 224, 3) (1280, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Create batches of fake data\n",
    "fake_input_data_cl, fake_input_data_cf = give_fake_data(BATCH_SIZE*BATCHES_GPU)\n",
    "print(fake_input_data_cl.shape, fake_input_data_cf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download Resnet weights\n",
    "path='http://data.mxnet.io/models/imagenet/'\n",
    "mx.test_utils.download(path+'resnet/50-layers/resnet-50-symbol.json')\n",
    "mx.test_utils.download(path+'resnet/50-layers/resnet-50-0000.params')\n",
    "print(\"Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)\n",
    "# List the last 10 layers\n",
    "all_layers = sym.get_internals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last layer\n",
    "flatten_layer = all_layers['flatten0_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize, ctx):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = nd.zeros((len(data), RESNET_FEATURES), dtype=np.float32, ctx=ctx)    \n",
    "    for idx, dta in yield_mb_X(data, batchsize):\n",
    "        classifier.forward(Batch(data=[mx.nd.array(dta)]))\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = classifier.get_outputs()[0]\n",
    "    nd.waitall()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last layer\n",
    "fe_sym = all_layers['flatten0_output']\n",
    "# Initialise GPU\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=ctx, label_names=None)\n",
    "fe_mod.bind(for_training=False, inputs_need_grad=False,\n",
    "            data_shapes=[('data', (BATCH_SIZE,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_start = predict_fn(fe_mod, fake_input_data_cf, BATCH_SIZE, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 631 ms, total: 2.63 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = predict_fn(fe_mod, fake_input_data_cf, BATCH_SIZE, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images per second 609.5238095238095\n"
     ]
    }
   ],
   "source": [
    "print(\"Images per second {}\".format((BATCH_SIZE*BATCHES_GPU)/2.1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
