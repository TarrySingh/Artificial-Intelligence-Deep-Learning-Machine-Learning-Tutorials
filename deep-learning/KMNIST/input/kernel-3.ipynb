{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2a7f5b4920d48e9767e158af0963e7ba25d2337"
   },
   "source": [
    "Hello everyone! Today, we are here with another very cool dataset **KMNIST**, short for **Kuzushiji-MNIST**.  This dataset was showcased at NeurIPS 2018 along with a [paper](https://arxiv.org/pdf/1812.01718.pdf).  The dataset is actually divided into three categories:<br>\n",
    "* **Kuzushiji-MNIST** is a drop-in replacement for the MNIST dataset (28x28 grayscale, 70,000 images), provided in the original MNIST format as well as a NumPy format. Since MNIST restricts us to 10 classes, we chose one character to represent each of the 10 rows of Hiragana when creating Kuzushiji-MNIST.\n",
    "\n",
    "* **Kuzushiji-49**, as the name suggests, has 49 classes (28x28 grayscale, 270,912 images), is a much larger, but imbalanced dataset containing 48 Hiragana characters and one Hiragana iteration mark.\n",
    "\n",
    "* **Kuzushiji-Kanji** is an imbalanced dataset of total 3832 Kanji characters (64x64 grayscale, 140,426 images), ranging from 1,766 examples to only a single example per class.\n",
    "\n",
    "In this kernel, we will focus on the **Kuzushiji-MNIST**  dataset. For many years, researchers have been using MNIST as one of the standard datasets for benchmarking their algorithms. No doubt that MNIST is a very good dataset but given the advancements that we have achieved in deep learning in the last 5 years, it is high time to replace MNIST with a more challenging dataset.  The above point is fair but why KMNIST? What makes it unique? Why is it important?\n",
    "\n",
    "Actually,  cursive Kuzushiji (くずし字) was an integral part of Japanese culture in the pre-modernisation era. It has been used for more than 1000 years but with the reforms done by Japanese leaders in the Japanese education system in 1868 and the following years, Kuzushiji was no longer seen as an important part and as a result, it is no longer taught in the official school curriculum.  Now you may ask: \"So what? Japanese lost the script but with modernisation, such things are expected. Why do you think it is important at all?\"\n",
    "\n",
    "Fair question! As a result of the changes that were made in the education system, most Japanese cannot read books over 150 years old, written in cursive Kuzushiji style. Also, According to the General Catalog of National Books, there have been over 1.7 million books written or published in Japan prior to 1867 along with a billion of unregistered books. **Almost every book, no matter what, always provides some sort of knowledge**.  So, in short, we have a lot of knowledge lying around in those books but we don't have many people who are experts in reading and extracting information from them. Because of lack of domain experts, the process of digitizing that knowledge is slow. \n",
    "\n",
    "This dataset can help non-experts to develop systems that can be implemented to extract the information from those millions and billions of books. Deep learning can certainly be very useful in this task. If you want more info about the topic, I suggest reading that paper I mentioned above. Let's dive into the dataset now and see how different is it from MNIST.  \n",
    " \n",
    "![fun](https://pbs.twimg.com/media/DuKOQlXWoAAndWt.jpg:large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/46/08ab68936625400fe690684428d4db4764f49b406782cc133df1d0299d06/umap-0.1.1.tar.gz\n",
      "Building wheels for collected packages: umap\n",
      "  Running setup.py bdist_wheel for umap ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/deeplearn/.cache/pip/wheels/7b/29/33/b4d917dc95f69c0a060e2ab012d95e15db9ed4cc0b94ccac26\n",
      "Successfully built umap\n",
      "Installing collected packages: umap\n",
      "Successfully installed umap-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/fc/c56a7da8c23122b7c5325b941850013880a7a93c21dc95e2b1ecd4750108/imgaug-0.2.7-py3-none-any.whl (644kB)\n",
      "\u001b[K    100% |################################| 645kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Shapely (from imgaug)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\n",
      "\u001b[K    100% |################################| 1.5MB 13.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/deeplearn/.local/lib/python3.6/site-packages (from imgaug) (1.12.0)\n",
      "Requirement already satisfied: scipy in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from imgaug) (1.1.0)\n",
      "Requirement already satisfied: Pillow in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from imgaug) (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /home/deeplearn/.local/lib/python3.6/site-packages (from imgaug) (1.15.4)\n",
      "Requirement already satisfied: imageio in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from imgaug) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from imgaug) (2.2.2)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from imgaug) (0.13.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (2.6.1)\n",
      "Requirement already satisfied: pytz in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (2017.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (1.0.1)\n",
      "Requirement already satisfied: networkx>=1.8 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (2.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (0.5.2)\n",
      "Requirement already satisfied: setuptools in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (39.2.0)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug) (4.1.2)\n",
      "Installing collected packages: Shapely, imgaug\n",
      "Successfully installed Shapely-1.6.4.post2 imgaug-0.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "6a54d8a5e616b75f9fbbde74b7bceffecffc8a12",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# I don't like warnings, especially user warnings at all!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-15cad45b3c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"
     ]
    }
   ],
   "source": [
    "# Import some packages that we require\n",
    "import os\n",
    "import glob\n",
    "import umap\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import resnet50\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict, Counter\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For plotting within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Graphics in SVG format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# seaborn color palette \n",
    "color = sns.color_palette()\n",
    "\n",
    "# For REPRODUCIBILITY\n",
    "seed = 111\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb73524d5ff954712ef173b53bb484ac59224050",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let us define some paths first\n",
    "input_path = Path(\"../input\")\n",
    "\n",
    "# Path to training images and corresponding labels provided as numpy arrays\n",
    "kmnist_train_images_path = input_path/\"kmnist-train-imgs.npz\"\n",
    "kmnist_train_labels_path = input_path/\"kmnist-train-labels.npz\"\n",
    "\n",
    "# Path to the test images and corresponding labels\n",
    "kmnist_test_images_path = input_path/\"kmnist-test-imgs.npz\"\n",
    "kmnist_test_labels_path = input_path/\"kmnist-test-labels.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a856dce204df75c9e65a1c141e3fcfb1136f5aa"
   },
   "source": [
    "### Load the dataset<br>\n",
    "The focus of this kernel is going to be kmnisr, drop-in replacement for MNIST. So, we will be loading only that dataset. Also, KMNIST is provided in two formats: \n",
    "* Raw images and labels\n",
    "* Images and labels as numpy arrays stored in `npz` file format\n",
    "\n",
    "We will be using the `npz` files to load and process the data because it is much faster as well as the recommended way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "081987a99183032354e86caec4b415643d31654d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the training data from the corresponding npz files\n",
    "kmnist_train_images = np.load(kmnist_train_images_path)['arr_0']\n",
    "kmnist_train_labels = np.load(kmnist_train_labels_path)['arr_0']\n",
    "\n",
    "# Load the test data from the corresponding npz files\n",
    "kmnist_test_images = np.load(kmnist_test_images_path)['arr_0']\n",
    "kmnist_test_labels = np.load(kmnist_test_labels_path)['arr_0']\n",
    "\n",
    "print(f\"Number of training samples: {len(kmnist_train_images)} where each sample is of size: {kmnist_train_images.shape[1:]}\")\n",
    "print(f\"Number of test samples: {len(kmnist_test_images)} where each sample is of size: {kmnist_test_images.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b76d0bf767c982127c02d916e58efb7e6ae24be"
   },
   "source": [
    "### Labels and their distribution<br>\n",
    "As the dataset is a drop-in replacement for MNIST, it is expected that it will have 10 labels but for the sanity check, let's look into it and check how many samples for each label are there in  the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18f4f6b7e5a0c49274e4bd6c70852160778e5dd8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the unique labels\n",
    "labels = np.unique(kmnist_train_labels)\n",
    "\n",
    "# Get the frequency count for each label\n",
    "frequency_count = np.bincount(kmnist_train_labels)\n",
    "\n",
    "# Visualize \n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=labels, y=frequency_count);\n",
    "plt.title(\"Distribution of labels in KMNIST training data\", fontsize=16)\n",
    "plt.xlabel(\"Labels\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "884cfb91feaf75d2d98f94dcea725ac9ae94dcc7"
   },
   "source": [
    "### Quick sneak peek\n",
    "Before moving further, we will get some random samples for each label in the training data. We will look at how the images for each character(label) looks like and how much is the variation between samples of the same class. Given these samples without any prior, would you be able to group them correctly?   😛 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4e551f5fc793bf448d519e8622898024c4aa689",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see how the images for different labels look like\n",
    "random_samples = []\n",
    "for i in range(10):\n",
    "    samples = kmnist_train_images[np.where(kmnist_train_labels==i)][:3]\n",
    "    random_samples.append(samples)\n",
    "\n",
    "# Converting list into a numpy array\n",
    "random_samples = np.array(random_samples)\n",
    "\n",
    "# Visualize the samples\n",
    "f, ax = plt.subplots(10,3, figsize=(10,20))\n",
    "for i, j in enumerate(random_samples):\n",
    "    ax[i, 0].imshow(random_samples[i][0,:,:], cmap='gray')\n",
    "    ax[i, 1].imshow(random_samples[i][1,:,:], cmap='gray')\n",
    "    ax[i, 2].imshow(random_samples[i][2,:,:], cmap='gray')\n",
    "    \n",
    "    ax[i,0].set_title(str(i))\n",
    "    ax[i,0].axis('off')\n",
    "    ax[i,0].set_aspect('equal')\n",
    "    \n",
    "    ax[i,1].set_title(str(i))\n",
    "    ax[i,1].axis('off')\n",
    "    ax[i,1].set_aspect('equal')\n",
    "    \n",
    "    ax[i,2].set_title(str(i))\n",
    "    ax[i,2].axis('off')\n",
    "    ax[i,2].set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c54e97c754eb20347b53174df55aa5d473fdfd5"
   },
   "source": [
    "### t-SNE and UMAP\n",
    "Visulaizing high-dimensional data is always fun. Plus it can give you some basic insights about local and global relationships within the data, though it totally depends on your problem statement. Currently, there are two widely used algoritms that are used for visualuzing high dimesional data.\n",
    "* **[t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)**\n",
    "* **[UMAP](https://github.com/lmcinnes/umap)**\n",
    "\n",
    "We will be using both to visualize KMNIST here. t-SNE is very expensive to compute. Also, the sklearn implementation of t-SNE is very very slow. It runs on single core and takes too much of memory. That's why I will be limiting the number of samples to at max 5K for t-SNE. For UMAP, we will be using a bigger sample size, somwhere 30K to 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "078e99404916aa0a06de13f0579fcaaabc90a39c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Labels mapping\n",
    "labels_dict = dict([(0, u\"\\u304A\"), (1, u\"\\u304D\"), (2, u\"\\u3059\"), (3, u\"\\u3064\"),\n",
    "                    (4, u\"\\u306A\"), (5, u\"\\u306F\"), (6, u\"\\u307E\"), (7, u\"\\u3084\"),\n",
    "                    (8, u\"\\u308C\"), (9, u\"\\u3093\")])\n",
    "\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e975597f252ed7ace1a6fd3b44c6fba72ad05ade",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A handy-dandy function to get randomly sampled data \n",
    "def get_random_samples(nb_indices):\n",
    "    # Choose indices randomly \n",
    "    random_indices = np.random.choice(nb_indices, size=nb_indices, replace=False)\n",
    "\n",
    "    # Get the data corresponding to these indices\n",
    "    random_train_images = kmnist_train_images[random_indices].astype(np.float32)\n",
    "    random_train_images /=255.\n",
    "    random_train_images = random_train_images.reshape(nb_indices, 28*28)\n",
    "    random_train_labels = kmnist_train_labels[random_indices]\n",
    "    labels = np.unique(random_train_labels)\n",
    "    return random_indices, random_train_images, random_train_labels, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20c87f926eecdff7e327e4021331c25e82144fcd",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get randomly sampled data\n",
    "nb_indices = 5000\n",
    "random_indices, random_train_images, random_train_labels, labels = get_random_samples(nb_indices)\n",
    "\n",
    "# Get the actual labels from the labels dictionary\n",
    "labels_name = [labels_dict[x] for x in labels]\n",
    "\n",
    "# Get a t-SNE instance\n",
    "tsne = TSNE(n_components=2, random_state=seed, perplexity=30)\n",
    "\n",
    "# Fit tsne to the data\n",
    "random_train_2D = tsne.fit_transform(random_train_images)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, label in zip(labels, labels_name):\n",
    "    sns.scatterplot(random_train_2D[random_train_labels == i, 0], \n",
    "                random_train_2D[random_train_labels == i, 1], \n",
    "                label=i, s=18)\n",
    "\n",
    "plt.title(\"Visualizating KMNIST embeddings using tSNE\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "380068b6c15c6020590ebb390ee531e059b2fd85",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try UMAP now.\n",
    "nb_indices = 10000\n",
    "random_indices, random_train_images, random_train_labels, labels = get_random_samples(nb_indices)\n",
    "\n",
    "embedding = umap.UMAP(n_components=2, metric='correlation', min_dist=0.8)\n",
    "random_train_2D = embedding.fit_transform(random_train_images)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111) #projection='3d')\n",
    "\n",
    "for i, label in zip(labels, labels):\n",
    "    sns.scatterplot(random_train_2D[random_train_labels == i, 0], \n",
    "                random_train_2D[random_train_labels == i, 1], \n",
    "                label=label, s=15)\n",
    "plt.title(\"Visualiza KMNIST embeddings using UMAP \", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b61196eb07585275528e0db840d8e30d17e980fa"
   },
   "source": [
    "If you look at the embeddings, you can actually see why this problem is much harder than solving simple MNIST. If you haven't seen t-SNE  and UMAP embeddings for MNIST, I will show you right here.\n",
    "\n",
    "MNIST embeddings using t-SNE\n",
    "![tsne](https://in.mathworks.com/help/examples/stats/win64/VisualizeHighDimensionalDataUsingTSNEExample_01.png)\n",
    "![umap](https://raw.githubusercontent.com/lmcinnes/umap/master/images/umap_example_mnist1.png)\n",
    "\n",
    "Both the algoritms can perfectly separate labels into different clusters but in KMNIST the clusters aren't that clear. Why do you think is the case with KMNIST? Just think about it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c265e21a87ad4b1683f6504a7ddb05b41d38c82"
   },
   "source": [
    "### Reproducing the results provided in the paper.\n",
    "In the paper, it has been mentioned that a simple CNN used in Keras examples for MNIST achieves a score of 99.06%, in terms of accuracy,  while on KMNIST, the same network is able to achieve only ~95% of accuracy, Let's validate the results. \n",
    "We will copy the [code](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) given in the keras repo for MNIST. We will train the network on KMNIST and check the final accuracy on the test set. Let's do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87aed116a7458971d19d99ef3928b939a52a8a03",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A bunch of variables. The variable have the same value as given in the keras example\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# input shape\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e12f8c5c0cdabd55d95c358050a1f5455e25c6ac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process the train and test data in the exact same manner as done for MNIST\n",
    "x_train = kmnist_train_images.astype('float32')\n",
    "x_test = kmnist_test_images.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], *input_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], *input_shape)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(kmnist_train_labels, num_classes)\n",
    "y_test = to_categorical(kmnist_test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5e3deac2359db1f48acd3c7278bb592a2f466d4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build and train the model. \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c248a603cdd6243ac2e9199b843b9b91d66fbed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the test loss and test accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10044df6ceea853691b4a698a399a1e359c7298e"
   },
   "source": [
    "Awesome. As reported in the paper, the results are fully reproducible. There is a huge gap  between the accuracy on MNIST and KMNIST. The same algorithm which scores `99.06%` on MNIST is able to score only `~95%` on KMNIST. This again proves the point that KMNIST is the perfect replacement for research and SOTA purposes as well. \n",
    "\n",
    "That's it folks. Hope you enjoyed the kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21fb603c5fb0b870d760df3637af98d78c59b4ec",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
